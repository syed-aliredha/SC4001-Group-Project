{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w_xZihHU-0L"
      },
      "source": [
        "# 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ-YCKOQUuC2",
        "outputId": "8f3d4aa2-74e4-4d83-b484-cd9031d261b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets torch\n",
        "!apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AqY1NS-vke7"
      },
      "source": [
        "# 2. Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6fb7dBWAUPf",
        "outputId": "360a3320-3dd2-4265-cff9-2e23568c16ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizerFast\n",
        "import time\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "MAX_LEN = 256\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_LAYERS = 2\n",
        "EPOCHS = 20\n",
        "EMBED_DIM = 128\n",
        "NUM_CLASSES = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, split):\n",
        "        self.texts = dataset[split]['text']\n",
        "        self.labels = dataset[split]['label']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded = tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoded['input_ids'].squeeze(0)\n",
        "        return input_ids, torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "train_data = IMDBDataset('train')\n",
        "test_data = IMDBDataset('test')\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "print(len(train_loader.dataset.labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVFK0VZ3PcMg"
      },
      "source": [
        "# 3. Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da_Jx38FH3Rn",
        "outputId": "ace31303-fd0c-4ed7-b6c1-ba7d114b2a97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BiLSTMClassifier(\n",
              "  (embedding): Embedding(30522, 128, padding_idx=0)\n",
              "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class BiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=tokenizer.pad_token_id)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        # Concatenate last hidden states for forward and backward LSTM\n",
        "        hn = torch.cat((hn[-2], hn[-1]), dim=1)  \n",
        "        return self.fc(hn)\n",
        "\n",
        "\n",
        "model = BiLSTMClassifier(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_classes=NUM_CLASSES\n",
        ").to(device)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9d4fLrfIEK8",
        "outputId": "017dc417-e2d3-453b-e8d6-38f1ab6fe5e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 4566786\n"
          ]
        }
      ],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Number of trainable parameters:\", pytorch_total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgoh1Z5hH-BH",
        "outputId": "b28afdfc-7056-45f2-809f-5e883db7ec0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train Acc: 62.72% | Time: 49.4s\n",
            "Test Acc: 66.91%\n",
            "\n",
            "Epoch 2/20\n",
            "Train Acc: 77.91% | Time: 49.0s\n",
            "Test Acc: 76.90%\n",
            "\n",
            "Epoch 3/20\n",
            "Train Acc: 83.56% | Time: 49.2s\n",
            "Test Acc: 82.49%\n",
            "\n",
            "Epoch 4/20\n",
            "Train Acc: 87.78% | Time: 48.3s\n",
            "Test Acc: 83.24%\n",
            "\n",
            "Epoch 5/20\n",
            "Train Acc: 91.02% | Time: 49.1s\n",
            "Test Acc: 84.56%\n",
            "\n",
            "Epoch 6/20\n",
            "Train Acc: 93.93% | Time: 49.3s\n",
            "Test Acc: 85.10%\n",
            "\n",
            "Epoch 7/20\n",
            "Train Acc: 96.01% | Time: 48.9s\n",
            "Test Acc: 84.83%\n",
            "\n",
            "Epoch 8/20\n",
            "Train Acc: 97.76% | Time: 48.8s\n",
            "Test Acc: 84.56%\n",
            "Early stopping!\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total, correct = 0, 0\n",
        "    start = time.time()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = outputs.argmax(1)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    print(f\"Train Acc: {correct/total*100:.2f}% | Time: {time.time() - start:.1f}s\")\n",
        "\n",
        "\n",
        "def evaluate(best_acc, patience):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            pred = outputs.argmax(1)\n",
        "            correct += (pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    acc = correct/total\n",
        "    print(f\"Test Acc: {acc*100:.2f}%\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        patience = 2\n",
        "    else:\n",
        "        patience -= 1\n",
        "    return best_acc, patience\n",
        "\n",
        "best_acc = 0\n",
        "patience = 2\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    train()\n",
        "    best_acc, patience = evaluate(best_acc, patience)\n",
        "\n",
        "    if patience == 0:\n",
        "      print(\"Early stopping!\")\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzzT_8CXTb5Q"
      },
      "source": [
        "Best accuracy obtained: 85.10%"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
