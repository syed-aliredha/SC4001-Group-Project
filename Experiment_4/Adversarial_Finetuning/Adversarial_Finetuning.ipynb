{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhdFE3gD3HcV",
        "outputId": "27b4cad5-80d6-4f05-db3c-6e7203f52f18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cDl5hXjUte9W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, get_linear_schedule_with_warmup, TrainingArguments, Trainer, EvalPrediction\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader, Sampler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the datasets\n",
        "print(\"Loading datasets...\")\n",
        "sst2 = load_dataset(\"glue\", \"sst2\")\n",
        "imdb = load_dataset(\"imdb\")\n",
        "\n",
        "# Load the pre-trained BERT model fine-tuned on IMDB\n",
        "model_name = \"yyammerrrss/imdb-sft-bert\"\n",
        "print(f\"Loading model from {model_name}...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DbmQ71h3Lkq",
        "outputId": "b01bf11d-3a48-4225-97a1-002f339908b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from yyammerrrss/imdb-sft-bert...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tokenization functions\n",
        "def tokenize_sst2(examples):\n",
        "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "def tokenize_imdb(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "# Tokenize the datasets\n",
        "print(\"Tokenizing datasets...\")\n",
        "tokenized_sst2 = {}\n",
        "for split in sst2:\n",
        "    tokenized_sst2[split] = sst2[split].map(tokenize_sst2, batched=True)\n",
        "    tokenized_sst2[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# For IMDB, we'll use both train and test sets\n",
        "tokenized_imdb = {}\n",
        "tokenized_imdb['train'] = imdb['train'].map(tokenize_imdb, batched=True)\n",
        "tokenized_imdb['test'] = imdb['test'].map(tokenize_imdb, batched=True)\n",
        "for split in tokenized_imdb:\n",
        "    tokenized_imdb[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "print(f\"SST2 train size: {len(tokenized_sst2['train'])}\")\n",
        "print(f\"SST2 validation size: {len(tokenized_sst2['validation'])}\")\n",
        "print(f\"IMDB train size: {len(tokenized_imdb['train'])}\")\n",
        "print(f\"IMDB test size: {len(tokenized_imdb['test'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz39o1Pa3Lm1",
        "outputId": "7919f6b9-90d7-4e03-fde3-725d63db37de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing datasets...\n",
            "SST2 train size: 67349\n",
            "SST2 validation size: 872\n",
            "IMDB train size: 25000\n",
            "IMDB test size: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the adversarial model architecture\n",
        "class AdversarialBert(nn.Module):\n",
        "    def __init__(self, bert_model_name, num_labels=2, lambda_param=0.1):\n",
        "        super(AdversarialBert, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "        self.domain_classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
        "        self.lambda_param = lambda_param\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None, domain_labels=None, alpha=1.0):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        # Task classifier (sentiment)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        # Domain classifier with gradient reversal\n",
        "        if self.training and domain_labels is not None:\n",
        "            # Apply gradient reversal\n",
        "            reverse_feature = GradientReversalFunction.apply(pooled_output, alpha)\n",
        "            domain_logits = self.domain_classifier(reverse_feature)\n",
        "\n",
        "            # Calculate losses\n",
        "            task_loss = F.cross_entropy(logits, labels)\n",
        "            domain_loss = F.cross_entropy(domain_logits, domain_labels)\n",
        "            loss = task_loss + self.lambda_param * domain_loss\n",
        "\n",
        "            return {\n",
        "                'loss': loss,\n",
        "                'task_logits': logits,\n",
        "                'domain_logits': domain_logits,\n",
        "                'task_loss': task_loss,\n",
        "                'domain_loss': domain_loss\n",
        "            }\n",
        "        else:\n",
        "            # During evaluation, only use the task classifier\n",
        "            loss = F.cross_entropy(logits, labels) if labels is not None else None\n",
        "            return {\n",
        "                'loss': loss,\n",
        "                'task_logits': logits\n",
        "            }\n",
        "\n",
        "# Define gradient reversal layer for adversarial training\n",
        "class GradientReversalFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.clone()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return -ctx.alpha * grad_output, None\n",
        "\n",
        "# Function to create dataloaders for adversarial training\n",
        "def create_adversarial_dataloader(source_dataset, target_dataset, batch_size):\n",
        "    # Create domain labels: 0 for source domain (IMDB), 1 for target domain (SST2)\n",
        "    source_domain_labels = torch.zeros(len(source_dataset), dtype=torch.long)\n",
        "    target_domain_labels = torch.ones(len(target_dataset), dtype=torch.long)\n",
        "\n",
        "    # Sample from the source dataset to match the size of the target dataset\n",
        "    source_indices = np.random.choice(len(source_dataset), min(len(source_dataset), len(target_dataset)), replace=False)\n",
        "    source_indices = [int(idx) for idx in source_indices]  # Convert numpy.int64 to Python int\n",
        "\n",
        "    # For IMDB (source), truncate the tensors to match SST2's length (128)\n",
        "    source_data = {\n",
        "        'input_ids': torch.stack([source_dataset[i]['input_ids'][:128] for i in source_indices]),\n",
        "        'attention_mask': torch.stack([source_dataset[i]['attention_mask'][:128] for i in source_indices]),\n",
        "        'labels': torch.stack([source_dataset[i]['label'] for i in source_indices]),\n",
        "        'domain_labels': source_domain_labels[source_indices]\n",
        "    }\n",
        "\n",
        "    # Get all target data (SST2)\n",
        "    target_data = {\n",
        "        'input_ids': torch.stack([target_dataset[i]['input_ids'] for i in range(len(target_dataset))]),\n",
        "        'attention_mask': torch.stack([target_dataset[i]['attention_mask'] for i in range(len(target_dataset))]),\n",
        "        'labels': torch.stack([target_dataset[i]['label'] for i in range(len(target_dataset))]),\n",
        "        'domain_labels': target_domain_labels\n",
        "    }\n",
        "\n",
        "    # Combine source and target data\n",
        "    combined_input_ids = torch.cat([source_data['input_ids'], target_data['input_ids']], dim=0)\n",
        "    combined_attention_mask = torch.cat([source_data['attention_mask'], target_data['attention_mask']], dim=0)\n",
        "    combined_labels = torch.cat([source_data['labels'], target_data['labels']], dim=0)\n",
        "    combined_domain_labels = torch.cat([source_data['domain_labels'], target_domain_labels], dim=0)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = TensorDataset(combined_input_ids, combined_attention_mask, combined_labels, combined_domain_labels)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "c4gXnoG63LpG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation function\n",
        "def evaluate_model(model, eval_dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_dataloader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            logits = outputs['task_logits']\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Create evaluation dataloaders\n",
        "def create_eval_dataloader(dataset, batch_size):\n",
        "    # Check if this is the IMDB dataset, which has length 512\n",
        "    first_input_ids = dataset[0]['input_ids']\n",
        "\n",
        "    if len(first_input_ids) > 128:\n",
        "        input_ids = torch.stack([dataset[i]['input_ids'][:128] for i in range(len(dataset))])\n",
        "        attention_mask = torch.stack([dataset[i]['attention_mask'][:128] for i in range(len(dataset))])\n",
        "    else:\n",
        "        input_ids = torch.stack([dataset[i]['input_ids'] for i in range(len(dataset))])\n",
        "        attention_mask = torch.stack([dataset[i]['attention_mask'] for i in range(len(dataset))])\n",
        "\n",
        "    labels = torch.stack([dataset[i]['label'] for i in range(len(dataset))])\n",
        "\n",
        "    eval_dataset = TensorDataset(input_ids, attention_mask, labels)\n",
        "    eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size)\n",
        "\n",
        "    return eval_dataloader"
      ],
      "metadata": {
        "id": "7ywsIExC3LrS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training function\n",
        "def train_adversarial(source_train, target_train, target_val, target_test, lambda_param=0.1,\n",
        "                      batch_size=16, num_epochs=3, learning_rate=2e-5, weight_decay=0.01):\n",
        "    # Initialize model\n",
        "    model = AdversarialBert(model_name, lambda_param=lambda_param)\n",
        "    model.to(device)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = create_adversarial_dataloader(source_train, target_train, batch_size)\n",
        "    target_val_dataloader = create_eval_dataloader(target_val, batch_size)\n",
        "    target_test_dataloader = create_eval_dataloader(target_test, batch_size)\n",
        "\n",
        "    # Initialize optimizer and scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    total_steps = len(train_dataloader) * num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Starting adversarial training...\")\n",
        "    best_val_accuracy = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_task_loss = 0\n",
        "        epoch_domain_loss = 0\n",
        "\n",
        "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch in progress_bar:\n",
        "            input_ids, attention_mask, labels, domain_labels = [b.to(device) for b in batch]\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate p value for increasing domain influence over time\n",
        "            p = float(epoch) / num_epochs\n",
        "            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels,\n",
        "                domain_labels=domain_labels,\n",
        "                alpha=alpha\n",
        "            )\n",
        "\n",
        "            # Backward pass\n",
        "            outputs['loss'].backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Update progress bar\n",
        "            epoch_loss += outputs['loss'].item()\n",
        "            epoch_task_loss += outputs['task_loss'].item()\n",
        "            epoch_domain_loss += outputs['domain_loss'].item()\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': epoch_loss / (progress_bar.n + 1),\n",
        "                'task_loss': epoch_task_loss / (progress_bar.n + 1),\n",
        "                'domain_loss': epoch_domain_loss / (progress_bar.n + 1)\n",
        "            })\n",
        "\n",
        "        # Evaluate on target validation set\n",
        "        print(f\"Evaluating on target validation set (epoch {epoch+1})...\")\n",
        "        val_metrics = evaluate_model(model, target_val_dataloader)\n",
        "        print(f\"Validation metrics: {val_metrics}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_metrics['accuracy'] > best_val_accuracy:\n",
        "            best_val_accuracy = val_metrics['accuracy']\n",
        "            print(f\"New best model with validation accuracy: {best_val_accuracy:.4f}\")\n",
        "            output_dir = \"./results/adversarial_finetuned\"\n",
        "            if not os.path.exists(output_dir):\n",
        "                os.makedirs(output_dir)\n",
        "            torch.save(model.state_dict(), os.path.join(output_dir, \"model.bin\"))\n",
        "\n",
        "    # Load best model for final evaluation\n",
        "    print(\"Loading best model for final evaluation...\")\n",
        "    model.load_state_dict(torch.load(os.path.join(output_dir, \"model.bin\")))\n",
        "\n",
        "    # Evaluate on target validation and test sets\n",
        "    print(\"Final evaluation on target validation set...\")\n",
        "    final_val_metrics = evaluate_model(model, target_val_dataloader)\n",
        "    print(f\"Final validation metrics: {final_val_metrics}\")\n",
        "\n",
        "    print(\"Evaluating on target test set...\")\n",
        "    final_test_metrics = evaluate_model(model, target_test_dataloader)\n",
        "    print(f\"Target test metrics: {final_test_metrics}\")\n",
        "\n",
        "    # Evaluate on source test set (IMDB)\n",
        "    print(\"Evaluating on source test set (IMDB)...\")\n",
        "    source_test_dataloader = create_eval_dataloader(tokenized_imdb['test'], batch_size)\n",
        "    source_test_metrics = evaluate_model(model, source_test_dataloader)\n",
        "    print(f\"Source test metrics: {source_test_metrics}\")\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'target_val_metrics': final_val_metrics,\n",
        "        'target_test_metrics': final_test_metrics,\n",
        "        'source_test_metrics': source_test_metrics\n",
        "    }\n",
        "\n",
        "# Run the adversarial training\n",
        "print(\"Starting adversarial finetuning experiment...\")\n",
        "results = train_adversarial(\n",
        "    source_train=tokenized_imdb['train'],\n",
        "    target_train=tokenized_sst2['train'],\n",
        "    target_val=tokenized_sst2['validation'],\n",
        "    target_test=tokenized_sst2['validation'],\n",
        "    batch_size=16,\n",
        "    num_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MowQwFKL3Ltb",
        "outputId": "8808768f-a4ec-49c7-a4a3-89564b028dca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting adversarial finetuning experiment...\n",
            "Starting adversarial training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 5772/5772 [07:55<00:00, 12.14it/s, loss=0.243, task_loss=0.203, domain_loss=0.398]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on target validation set (epoch 1)...\n",
            "Validation metrics: {'accuracy': 0.926605504587156, 'precision': 0.9377880184331797, 'recall': 0.9166666666666666, 'f1': 0.9271070615034168}\n",
            "New best model with validation accuracy: 0.9266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 5772/5772 [07:54<00:00, 12.15it/s, loss=0.259, task_loss=0.114, domain_loss=1.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on target validation set (epoch 2)...\n",
            "Validation metrics: {'accuracy': 0.9231651376146789, 'precision': 0.929384965831435, 'recall': 0.918918918918919, 'f1': 0.9241223103057757}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 5772/5772 [07:55<00:00, 12.15it/s, loss=0.125, task_loss=0.058, domain_loss=0.665]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on target validation set (epoch 3)...\n",
            "Validation metrics: {'accuracy': 0.9243119266055045, 'precision': 0.9108695652173913, 'recall': 0.9436936936936937, 'f1': 0.9269911504424779}\n",
            "Loading best model for final evaluation...\n",
            "Final evaluation on target validation set...\n",
            "Final validation metrics: {'accuracy': 0.926605504587156, 'precision': 0.9377880184331797, 'recall': 0.9166666666666666, 'f1': 0.9271070615034168}\n",
            "Evaluating on target test set...\n",
            "Target test metrics: {'accuracy': 0.926605504587156, 'precision': 0.9377880184331797, 'recall': 0.9166666666666666, 'f1': 0.9271070615034168}\n",
            "Evaluating on source test set (IMDB)...\n",
            "Source test metrics: {'accuracy': 0.89308, 'precision': 0.8874694424729911, 'recall': 0.90032, 'f1': 0.8938485365950518}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display final results\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"ADVERSARIAL DOMAIN ADAPTATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"Target validation (SST2) results:\")\n",
        "print(f\"Accuracy: {results['target_val_metrics']['accuracy']:.4f}\")\n",
        "print(f\"F1 Score: {results['target_val_metrics']['f1']:.4f}\")\n",
        "print(f\"Precision: {results['target_val_metrics']['precision']:.4f}\")\n",
        "print(f\"Recall: {results['target_val_metrics']['recall']:.4f}\")\n",
        "\n",
        "print(f\"\\nSource test (IMDB) results:\")\n",
        "print(f\"Accuracy: {results['source_test_metrics']['accuracy']:.4f}\")\n",
        "print(f\"F1 Score: {results['source_test_metrics']['f1']:.4f}\")\n",
        "print(f\"Precision: {results['source_test_metrics']['precision']:.4f}\")\n",
        "print(f\"Recall: {results['source_test_metrics']['recall']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAUohO1B3L_f",
        "outputId": "5c1d8a8f-e9ad-4d77-baeb-56e42711e44c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "ADVERSARIAL DOMAIN ADAPTATION RESULTS\n",
            "================================================================================\n",
            "Target validation (SST2) results:\n",
            "Accuracy: 0.9266\n",
            "F1 Score: 0.9271\n",
            "Precision: 0.9378\n",
            "Recall: 0.9167\n",
            "\n",
            "Source test (IMDB) results:\n",
            "Accuracy: 0.8931\n",
            "F1 Score: 0.8938\n",
            "Precision: 0.8875\n",
            "Recall: 0.9003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that IMDB results have fallen a bit this could be due to truncation of the IMDB dataset to match the dimensions of the SST-2 dataset.Lets try a dynamic padding approach to try and reduce this and see our results"
      ],
      "metadata": {
        "id": "51zRKdBzwGVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Custom dataset that handles different sequence lengths\n",
        "class DynamicPaddingDataset(Dataset):\n",
        "    def __init__(self, source_dataset, target_dataset, source_domain_label=0, target_domain_label=1, balance=True):\n",
        "        self.source_dataset = source_dataset\n",
        "        self.target_dataset = target_dataset\n",
        "        self.source_domain_label = source_domain_label\n",
        "        self.target_domain_label = target_domain_label\n",
        "\n",
        "        if balance and len(source_dataset) > len(target_dataset):\n",
        "            # Sample indices from source to match target size\n",
        "            self.source_indices = np.random.choice(len(source_dataset), len(target_dataset), replace=False)\n",
        "            self.source_indices = [int(idx) for idx in self.source_indices]\n",
        "        else:\n",
        "            self.source_indices = list(range(len(source_dataset)))\n",
        "\n",
        "        self.source_size = len(self.source_indices)\n",
        "        self.target_size = len(target_dataset)\n",
        "        self.total_size = self.source_size + self.target_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Source examples come first, then target examples\n",
        "        if idx < self.source_size:\n",
        "            source_idx = self.source_indices[idx]\n",
        "            item = self.source_dataset[source_idx]\n",
        "            return {\n",
        "                'input_ids': item['input_ids'],\n",
        "                'attention_mask': item['attention_mask'],\n",
        "                'label': item['label'],\n",
        "                'domain_label': torch.tensor(self.source_domain_label, dtype=torch.long),\n",
        "                'is_source': True\n",
        "            }\n",
        "        else:\n",
        "            target_idx = idx - self.source_size\n",
        "            item = self.target_dataset[target_idx]\n",
        "            return {\n",
        "                'input_ids': item['input_ids'],\n",
        "                'attention_mask': item['attention_mask'],\n",
        "                'label': item['label'],\n",
        "                'domain_label': torch.tensor(self.target_domain_label, dtype=torch.long),\n",
        "                'is_source': False\n",
        "            }\n",
        "\n",
        "# Custom collate function for dynamic padding\n",
        "def dynamic_padding_collate_fn(batch):\n",
        "    # Separate source and target examples to process them differently\n",
        "    source_examples = [item for item in batch if item['is_source']]\n",
        "    target_examples = [item for item in batch if not item['is_source']]\n",
        "\n",
        "    # Process source examples (can be longer)\n",
        "    if source_examples:\n",
        "        source_max_len = max(len(ex['input_ids']) for ex in source_examples)\n",
        "        source_input_ids = []\n",
        "        source_attention_mask = []\n",
        "\n",
        "        for ex in source_examples:\n",
        "            # Pad or truncate to source_max_len\n",
        "            input_ids = ex['input_ids']\n",
        "            attention_mask = ex['attention_mask']\n",
        "\n",
        "            if len(input_ids) < source_max_len:\n",
        "                # Pad\n",
        "                padding_length = source_max_len - len(input_ids)\n",
        "                input_ids = torch.cat([input_ids, torch.zeros(padding_length, dtype=torch.long)])\n",
        "                attention_mask = torch.cat([attention_mask, torch.zeros(padding_length, dtype=torch.long)])\n",
        "            elif len(input_ids) > source_max_len:\n",
        "                # Truncate\n",
        "                input_ids = input_ids[:source_max_len]\n",
        "                attention_mask = attention_mask[:source_max_len]\n",
        "\n",
        "            source_input_ids.append(input_ids)\n",
        "            source_attention_mask.append(attention_mask)\n",
        "    else:\n",
        "        source_input_ids = []\n",
        "        source_attention_mask = []\n",
        "\n",
        "    # Process target examples (usually shorter)\n",
        "    if target_examples:\n",
        "        target_max_len = max(len(ex['input_ids']) for ex in target_examples)\n",
        "        target_input_ids = []\n",
        "        target_attention_mask = []\n",
        "\n",
        "        for ex in target_examples:\n",
        "            # Pad to target_max_len (no truncation needed as these are already properly sized)\n",
        "            input_ids = ex['input_ids']\n",
        "            attention_mask = ex['attention_mask']\n",
        "\n",
        "            if len(input_ids) < target_max_len:\n",
        "                # Pad\n",
        "                padding_length = target_max_len - len(input_ids)\n",
        "                input_ids = torch.cat([input_ids, torch.zeros(padding_length, dtype=torch.long)])\n",
        "                attention_mask = torch.cat([attention_mask, torch.zeros(padding_length, dtype=torch.long)])\n",
        "\n",
        "            target_input_ids.append(input_ids)\n",
        "            target_attention_mask.append(attention_mask)\n",
        "    else:\n",
        "        target_input_ids = []\n",
        "        target_attention_mask = []\n",
        "\n",
        "    # Combine all examples\n",
        "    all_input_ids = source_input_ids + target_input_ids\n",
        "    all_attention_mask = source_attention_mask + target_attention_mask\n",
        "    all_labels = [ex['label'] for ex in batch]\n",
        "    all_domain_labels = [ex['domain_label'] for ex in batch]\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids_tensor = torch.stack(all_input_ids) if all_input_ids else torch.tensor([])\n",
        "    attention_mask_tensor = torch.stack(all_attention_mask) if all_attention_mask else torch.tensor([])\n",
        "    labels_tensor = torch.stack(all_labels)\n",
        "    domain_labels_tensor = torch.stack(all_domain_labels)\n",
        "\n",
        "    return input_ids_tensor, attention_mask_tensor, labels_tensor, domain_labels_tensor\n",
        "\n",
        "# Custom batch sampler that creates mini-batches with similar sequence lengths\n",
        "class SimilarLengthBatchSampler(Sampler):\n",
        "    def __init__(self, dataset, batch_size, shuffle=True, drop_last=False):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "        # Group indices by sequence length\n",
        "        self.length_buckets = defaultdict(list)\n",
        "\n",
        "        # Process source examples\n",
        "        for idx in range(dataset.source_size):\n",
        "            source_idx = dataset.source_indices[idx]\n",
        "            length = len(dataset.source_dataset[source_idx]['input_ids'])\n",
        "            # Round length to nearest 32 to create reasonable buckets\n",
        "            bucket = (length // 32) * 32\n",
        "            self.length_buckets[bucket].append(idx)\n",
        "\n",
        "        # Process target examples\n",
        "        for idx in range(dataset.target_size):\n",
        "            target_idx = idx\n",
        "            length = len(dataset.target_dataset[target_idx]['input_ids'])\n",
        "            # Round length to nearest 32\n",
        "            bucket = (length // 32) * 32\n",
        "            self.length_buckets[bucket].append(idx + dataset.source_size)\n",
        "\n",
        "        # Calculate number of batches\n",
        "        self.num_batches = sum(max(1, len(indices) // batch_size) for indices in self.length_buckets.values())\n",
        "        if not drop_last:\n",
        "            self.num_batches += sum(1 for indices in self.length_buckets.values() if len(indices) % batch_size > 0)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Shuffle within each bucket if required\n",
        "        if self.shuffle:\n",
        "            for bucket in self.length_buckets.values():\n",
        "                random.shuffle(bucket)\n",
        "\n",
        "        # Create batches\n",
        "        batches = []\n",
        "        for bucket, indices in self.length_buckets.items():\n",
        "            # Split indices into batches\n",
        "            for i in range(0, len(indices), self.batch_size):\n",
        "                if i + self.batch_size <= len(indices) or not self.drop_last:\n",
        "                    batches.append(indices[i:i + self.batch_size])\n",
        "\n",
        "        # Shuffle the batches\n",
        "        if self.shuffle:\n",
        "            random.shuffle(batches)\n",
        "\n",
        "        # Yield batches\n",
        "        for batch in batches:\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches\n",
        "\n",
        "# Function to create dataloaders with dynamic padding\n",
        "def create_dynamic_padding_dataloaders(source_train, target_train, target_val, target_test, batch_size=16):\n",
        "    # Create training dataset\n",
        "    train_dataset = DynamicPaddingDataset(\n",
        "        source_train, target_train,\n",
        "        source_domain_label=0, target_domain_label=1,\n",
        "        balance=True\n",
        "    )\n",
        "\n",
        "    # Create batch sampler for training\n",
        "    train_sampler = SimilarLengthBatchSampler(\n",
        "        train_dataset, batch_size=batch_size,\n",
        "        shuffle=True, drop_last=False\n",
        "    )\n",
        "\n",
        "    # Create training dataloader\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_sampler=train_sampler,\n",
        "        collate_fn=dynamic_padding_collate_fn,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    # Create validation and test dataloaders\n",
        "    # Note: For evaluation, we don't need domain labels\n",
        "    def create_eval_dataloader(dataset, batch_size):\n",
        "        eval_dataset = TensorDataset(\n",
        "            torch.stack([dataset[i]['input_ids'] for i in range(len(dataset))]),\n",
        "            torch.stack([dataset[i]['attention_mask'] for i in range(len(dataset))]),\n",
        "            torch.stack([dataset[i]['label'] for i in range(len(dataset))])\n",
        "        )\n",
        "        return DataLoader(eval_dataset, batch_size=batch_size)\n",
        "\n",
        "    target_val_dataloader = create_eval_dataloader(target_val, batch_size)\n",
        "    target_test_dataloader = create_eval_dataloader(target_test, batch_size)\n",
        "\n",
        "    return {\n",
        "        'train': train_dataloader,\n",
        "        'val': target_val_dataloader,\n",
        "        'test': target_test_dataloader\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "6tB5surAwaKT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified training function to use dynamic padding\n",
        "# Modified training function to use dynamic padding\n",
        "def train_adversarial_with_dynamic_padding(source_train, target_train, target_val, target_test, lambda_param=0.1,\n",
        "                                          batch_size=16, num_epochs=3, learning_rate=2e-5, weight_decay=0.01):\n",
        "    # Track training time\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize model\n",
        "    model = AdversarialBert(model_name, lambda_param=lambda_param)\n",
        "    model.to(device)\n",
        "\n",
        "    # Create dataloaders with dynamic padding\n",
        "    dataloaders = create_dynamic_padding_dataloaders(\n",
        "        source_train, target_train, target_val, target_test, batch_size\n",
        "    )\n",
        "\n",
        "    # Initialize optimizer and scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    total_steps = len(dataloaders['train']) * num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Starting adversarial training with dynamic padding...\")\n",
        "    best_val_accuracy = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_task_loss = 0\n",
        "        epoch_domain_loss = 0\n",
        "\n",
        "        progress_bar = tqdm(dataloaders['train'], desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch in progress_bar:\n",
        "            input_ids, attention_mask, labels, domain_labels = [b.to(device) for b in batch]\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate p value for increasing domain influence over time\n",
        "            p = float(epoch) / num_epochs\n",
        "            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels,\n",
        "                domain_labels=domain_labels,\n",
        "                alpha=alpha\n",
        "            )\n",
        "\n",
        "            # Backward pass\n",
        "            outputs['loss'].backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Update progress bar\n",
        "            epoch_loss += outputs['loss'].item()\n",
        "            epoch_task_loss += outputs['task_loss'].item()\n",
        "            epoch_domain_loss += outputs['domain_loss'].item()\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': epoch_loss / (progress_bar.n + 1),\n",
        "                'task_loss': epoch_task_loss / (progress_bar.n + 1),\n",
        "                'domain_loss': epoch_domain_loss / (progress_bar.n + 1)\n",
        "            })\n",
        "\n",
        "        # Calculate epoch time\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        # Evaluate on target validation set\n",
        "        print(f\"Evaluating on target validation set (epoch {epoch+1})...\")\n",
        "        val_metrics = evaluate_model(model, dataloaders['val'])\n",
        "        print(f\"Validation metrics: {val_metrics}\")\n",
        "        print(f\"Epoch {epoch+1} time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_metrics['accuracy'] > best_val_accuracy:\n",
        "            best_val_accuracy = val_metrics['accuracy']\n",
        "            print(f\"New best model with validation accuracy: {best_val_accuracy:.4f}\")\n",
        "            output_dir = \"./results/adversarial_dynamic_padding\"\n",
        "            if not os.path.exists(output_dir):\n",
        "                os.makedirs(output_dir)\n",
        "            torch.save(model.state_dict(), os.path.join(output_dir, \"model.bin\"))\n",
        "\n",
        "    # Load best model for final evaluation\n",
        "    print(\"Loading best model for final evaluation...\")\n",
        "    model.load_state_dict(torch.load(os.path.join(output_dir, \"model.bin\")))\n",
        "\n",
        "    # Evaluate on target validation and test sets\n",
        "    print(\"Final evaluation on target validation set...\")\n",
        "    final_val_metrics = evaluate_model(model, dataloaders['val'])\n",
        "    print(f\"Final validation metrics: {final_val_metrics}\")\n",
        "\n",
        "    print(\"Evaluating on target test set...\")\n",
        "    final_test_metrics = evaluate_model(model, dataloaders['test'])\n",
        "    print(f\"Target test metrics: {final_test_metrics}\")\n",
        "\n",
        "    # Evaluate on source test set (IMDB)\n",
        "    print(\"Evaluating on source test set (IMDB)...\")\n",
        "    # Create a standard dataloader for IMDB test set evaluation\n",
        "\n",
        "    # Helper function to pad sequences to max length in batch\n",
        "    def pad_sequences(batch):\n",
        "        input_ids = [item['input_ids'] for item in batch]\n",
        "        attention_mask = [item['attention_mask'] for item in batch]\n",
        "        labels = [item['label'] for item in batch]\n",
        "\n",
        "        max_len = max(len(ids) for ids in input_ids)\n",
        "\n",
        "        # Pad sequences\n",
        "        padded_input_ids = []\n",
        "        padded_attention_mask = []\n",
        "\n",
        "        for ids, mask in zip(input_ids, attention_mask):\n",
        "            if len(ids) < max_len:\n",
        "                padding_len = max_len - len(ids)\n",
        "                padded_input_ids.append(torch.cat([ids, torch.zeros(padding_len, dtype=torch.long)]))\n",
        "                padded_attention_mask.append(torch.cat([mask, torch.zeros(padding_len, dtype=torch.long)]))\n",
        "            else:\n",
        "                padded_input_ids.append(ids)\n",
        "                padded_attention_mask.append(mask)\n",
        "\n",
        "        return (\n",
        "            torch.stack(padded_input_ids),\n",
        "            torch.stack(padded_attention_mask),\n",
        "            torch.stack(labels)\n",
        "        )\n",
        "\n",
        "    # Create dataloader for IMDB test set\n",
        "    class SimpleDataset(Dataset):\n",
        "        def __init__(self, dataset):\n",
        "            self.dataset = dataset\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dataset)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return self.dataset[idx]\n",
        "\n",
        "    imdb_test_dataset = SimpleDataset(tokenized_imdb['test'])\n",
        "\n",
        "    imdb_test_dataloader = DataLoader(\n",
        "        imdb_test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=pad_sequences\n",
        "    )\n",
        "\n",
        "    source_test_metrics = evaluate_model(model, imdb_test_dataloader)\n",
        "    print(f\"Source test metrics: {source_test_metrics}\")\n",
        "\n",
        "    # Calculate total training time\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'target_val_metrics': final_val_metrics,\n",
        "        'target_test_metrics': final_test_metrics,\n",
        "        'source_test_metrics': source_test_metrics,\n",
        "        'training_time': training_time\n",
        "    }"
      ],
      "metadata": {
        "id": "lTz-AtCozFhZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the adversarial training with dynamic padding\n",
        "print(\"Starting adversarial finetuning with dynamic padding...\")\n",
        "results = train_adversarial_with_dynamic_padding(\n",
        "    source_train=tokenized_imdb['train'],\n",
        "    target_train=tokenized_sst2['train'],\n",
        "    target_val=tokenized_sst2['validation'],\n",
        "    target_test=tokenized_sst2['validation'],\n",
        "    batch_size=16,\n",
        "    num_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wcdYoczzP66",
        "outputId": "de96b5b3-bb4c-4ba9-ad0d-660041ec3497"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting adversarial finetuning with dynamic padding...\n",
            "Starting adversarial training with dynamic padding...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 5773/5773 [14:18<00:00,  6.72it/s, loss=0.203, task_loss=0.159, domain_loss=0.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on target validation set (epoch 1)...\n",
            "Validation metrics: {'accuracy': 0.9311926605504587, 'precision': 0.9343891402714932, 'recall': 0.9301801801801802, 'f1': 0.9322799097065463}\n",
            "Epoch 1 time: 858.60 seconds\n",
            "New best model with validation accuracy: 0.9312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 5773/5773 [14:18<00:00,  6.73it/s, loss=0.226, task_loss=0.0836, domain_loss=1.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on target validation set (epoch 2)...\n",
            "Validation metrics: {'accuracy': 0.9231651376146789, 'precision': 0.927437641723356, 'recall': 0.9211711711711712, 'f1': 0.9242937853107345}\n",
            "Epoch 2 time: 858.08 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 5773/5773 [14:19<00:00,  6.71it/s, loss=0.114, task_loss=0.045, domain_loss=0.692]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on target validation set (epoch 3)...\n",
            "Validation metrics: {'accuracy': 0.9277522935779816, 'precision': 0.9261744966442953, 'recall': 0.9324324324324325, 'f1': 0.9292929292929293}\n",
            "Epoch 3 time: 860.00 seconds\n",
            "Loading best model for final evaluation...\n",
            "Final evaluation on target validation set...\n",
            "Final validation metrics: {'accuracy': 0.9311926605504587, 'precision': 0.9343891402714932, 'recall': 0.9301801801801802, 'f1': 0.9322799097065463}\n",
            "Evaluating on target test set...\n",
            "Target test metrics: {'accuracy': 0.9311926605504587, 'precision': 0.9343891402714932, 'recall': 0.9301801801801802, 'f1': 0.9322799097065463}\n",
            "Evaluating on source test set (IMDB)...\n",
            "Source test metrics: {'accuracy': 0.9388, 'precision': 0.9381690365873143, 'recall': 0.93952, 'f1': 0.9388440322967463}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display final results\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"ADVERSARIAL DOMAIN ADAPTATION RESULTS WITH DYNAMIC PADDING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"Target validation (SST2) results:\")\n",
        "print(f\"Accuracy: {results['target_val_metrics']['accuracy']:.4f}\")\n",
        "print(f\"F1 Score: {results['target_val_metrics']['f1']:.4f}\")\n",
        "print(f\"Precision: {results['target_val_metrics']['precision']:.4f}\")\n",
        "print(f\"Recall: {results['target_val_metrics']['recall']:.4f}\")\n",
        "\n",
        "print(f\"\\nSource test (IMDB) results:\")\n",
        "print(f\"Accuracy: {results['source_test_metrics']['accuracy']:.4f}\")\n",
        "print(f\"F1 Score: {results['source_test_metrics']['f1']:.4f}\")\n",
        "print(f\"Precision: {results['source_test_metrics']['precision']:.4f}\")\n",
        "print(f\"Recall: {results['source_test_metrics']['recall']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-Ub0bFq7EmI",
        "outputId": "e714ffd9-aa47-4429-cb48-cf4365bd1bf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "ADVERSARIAL DOMAIN ADAPTATION RESULTS WITH DYNAMIC PADDING\n",
            "================================================================================\n",
            "Target validation (SST2) results:\n",
            "Accuracy: 0.9312\n",
            "F1 Score: 0.9323\n",
            "Precision: 0.9344\n",
            "Recall: 0.9302\n",
            "\n",
            "Source test (IMDB) results:\n",
            "Accuracy: 0.9388\n",
            "F1 Score: 0.9388\n",
            "Precision: 0.9382\n",
            "Recall: 0.9395\n"
          ]
        }
      ]
    }
  ]
}