{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w_xZihHU-0L"
      },
      "source": [
        "# 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ-YCKOQUuC2"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install datasets transformers evaluate optuna peft\n",
        "!apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY-kD29mU7rJ"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "from datasets import load_dataset\n",
        "imdb = load_dataset(\"imdb\")\n",
        "print(imdb)\n",
        "\n",
        "train_dataset = imdb['train'].shuffle(seed=42)\n",
        "test_dataset = imdb['test'].shuffle(seed=42)\n",
        "\n",
        "# For hyperparameter tuning\n",
        "val_split_ratio = 0.3\n",
        "val_size = int(len(imdb[\"train\"]) * val_split_ratio)\n",
        "\n",
        "val_dataset_ht = train_dataset.select([i for i in list(range(val_size))])\n",
        "train_dataset_ht = train_dataset.select([i for i in list(range(val_size, len(imdb[\"train\"])))])\n",
        "\n",
        "print(len(test_dataset))\n",
        "print(len(val_dataset_ht))\n",
        "print(len(train_dataset_ht))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wUTi_mkVuAH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import optuna\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers.models.auto import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
        "import evaluate\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "CHECKPOINT = \"microsoft/deberta-v3-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
        "\n",
        "train_dataset_ht = train_dataset_ht.map(tokenize_function, batched=True)\n",
        "val_dataset_ht = val_dataset_ht.map(tokenize_function, batched=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYX1JT5mWQE8"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "config = AutoConfig.from_pretrained(CHECKPOINT, num_labels=2)\n",
        "\n",
        "def objective(trial: optuna.Trial):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, config=config)\n",
        "\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16, 32])\n",
        "    learning_rate = trial.suggest_categorical('learning_rate', [5e-5, 3e-5, 2e-5])\n",
        "    num_epochs = trial.suggest_categorical('num_epochs', [2, 3, 4])\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=num_epochs\n",
        "        )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset_ht,\n",
        "        eval_dataset=val_dataset_ht)\n",
        "\n",
        "    trainer.train()\n",
        "    # Evaluate the model on the validation dataset\n",
        "    eval_result = trainer.evaluate()\n",
        "\n",
        "    # Return validation loss (you can add other metrics here as needed)\n",
        "    return eval_result[\"eval_loss\"]\n",
        "\n",
        "\n",
        "study = optuna.create_study(study_name='hp-search-deberta', direction='minimize')\n",
        "study.optimize(func=objective, n_trials=5)\n",
        "\n",
        "best_lr = float(study.best_params['learning_rate'])\n",
        "best_batch_size = study.best_params['batch_size']\n",
        "best_epoch = int(study.best_params['num_epochs'])\n",
        "\n",
        "print(f\"Best Learning Rate: {best_lr}\")\n",
        "print(f\"Best Batch Size: {best_batch_size}\")\n",
        "print(f\"Best Epochs: {best_epoch}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7ZKAKSiWVJe"
      },
      "outputs": [],
      "source": [
        "# Define evaluation metrics\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "    recall = recall_metric.compute(predictions=predictions, references=labels)[\"recall\"]\n",
        "    precision = precision_metric.compute(predictions=predictions, references=labels)[\"precision\"]\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1, \"recall\": recall, \"precision\": precision}\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=2)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=best_lr,\n",
        "    per_device_train_batch_size=best_batch_size,\n",
        "    per_device_eval_batch_size=best_batch_size,\n",
        "    num_train_epochs=best_epoch\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "train_results = trainer.train()\n",
        "print(train_results)\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n",
        "\n",
        "\n",
        "trainer.save_model(\"./best-deberta-model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
